---
title: "R Notebook"
output: html_notebook
---


Trend analysis of leatherback turtles nesting in Florida, Puerto Rico, and St Croix with Kelly Stewart.

In this version (v2), I use the negative binomial distribution instead of Poisson because Poisson resulted in high Pareto k statistics for some beaches in FL. Negative binomial distribution should be a bit more flexible than Poisson. We'll see how it works... 

New data were received in August 2020. 

```{r}
rm(list=ls())
library(tidyverse)
library(ggplot2)
library(readr)
library(lubridate)
library(jagsUI)
library(bayesplot)
library(stringr)

source("Caribbean_Dc_fcns.R")

MCMC.params <- list(n.samples = 50000,
                    n.burnin = 30000,
                    n.thin = 5,
                    n.chains = 5)

n.per.chain <- (MCMC.params$n.samples - MCMC.params$n.burnin)/MCMC.params$n.thin

```

Get data;

```{r}
col.def <- cols(ID = col_integer(),
                year = col_integer(),
                beach = col_character(),
                latitude = col_double(),
                distance = col_double(),
                days_week = col_integer(),
                days_year = col_integer(),
                nests = col_integer())

FL.nest.counts <- read_csv("data/FL_Sept2020.csv", 
                           col_types = col.def) %>% 
  mutate(beach_f = as.factor(toupper(beach)),
         dataset = "FL",
         ID2 = as.numeric(as.factor(ID)))

PR.nest.counts <- read_csv("data/PR_Sept2020.csv", 
                           col_types = col.def) %>% 
  mutate(beach_f = as.factor(toupper(beach)),
         dataset = "PR",
         ID2 = as.numeric(as.factor(ID)))

STX.nest.counts <- read_csv("data/STX_Sept2020.csv", 
                           col_types = col.def) %>% 
  mutate(beach_f = as.factor(toupper(beach)),
         dataset = "STX",
         ID2 = as.numeric(as.factor(ID)))


```

Change in abundance over time at each beach can be seen in FL_PR_STX_v0_Sept2020.Rmd. 

For FL, we can fit the same models as the last publication. I use the same set of covariates but also test all possibilities of 3 covariates to see which set is the best.  

```{r}

FL.nest.counts %>% 
  group_by(ID2) %>%
  summarise(n = n()) -> FL.ns

FL.nest.counts %>% 
  select(ID2, ID, latitude, beach_f, year) %>% 
  group_by(ID) %>%
  summarise(ID2 = first(ID2),
            name = first(beach_f),
            latitude = first(latitude),
            median.yr = median(year),
            min.yr = min(year),
            n = n()) %>%
  mutate(latc = latitude - mean(latitude),
         latc2 = latc^2,
         beach = ID,
         ID2 = ID2,
         name = name) -> FL.lat.dat

median.yr <- select(FL.lat.dat, c(ID, median.yr, min.yr)) %>%
  right_join(FL.nest.counts, by = "ID") %>% 
  select(ID, median.yr, min.yr, year)

# changed from centering to left-adjusted for years. I think t >= 0 makes more
# sense explaining the intercept than centering time. With t >= 0, it is the 
# log(mu) at time 0 for each beach, whereas if time is centered, it is log(mu) at
# some arbitrary year for each beach. 

FL.jags.data <- list(N = length(FL.nest.counts$nests),
                     nbeach = length(unique(FL.nest.counts$ID2)),
                     count = FL.nest.counts$nests,
                     beach = FL.nest.counts$ID2,
                     yearc = median.yr$year - median.yr$min.yr,
                     latc = FL.lat.dat$latc,
                     latc2 = FL.lat.dat$latc2)

data.vector <- FL.jags.data$count %>% 
  rep(each = MCMC.params$n.chains * n.per.chain)

parameters <- c("a0", "a1", "beta", "B.hat", "a1pc",
                "mu.a0", "mu.a1", "r",
                "rea0", "rea1",
                "delta1", "delta2",
                "sigma.e", "Sigma.B",
                "sigma.a0", "sigma.a1",
                "floridapc", "probP", "deviance", "loglik")

```


```{r}
model.names <- c("3Covs", rep("2Covs", times = 3), rep("1Cov", times = 3), "0Cov")
out.names <- c("3Covs", "logD_DayWk", "logD_DayYr", "DayWk_DayYr",
               "logD", "DayWk", "DayYr", "0Cov") 
X.FL <- list(cbind(log(FL.nest.counts$distance) - median(log(FL.nest.counts$distance)),
                FL.nest.counts$days_week - median(FL.nest.counts$days_week),
                FL.nest.counts$days_year - median(FL.nest.counts$days_year)),
          cbind(log(FL.nest.counts$distance) - median(log(FL.nest.counts$distance)),
                FL.nest.counts$days_week - median(FL.nest.counts$days_week)),
          cbind(log(FL.nest.counts$distance) - median(log(FL.nest.counts$distance)),
                FL.nest.counts$days_year - median(FL.nest.counts$days_year)),
          cbind(FL.nest.counts$days_week - median(FL.nest.counts$days_week),
                FL.nest.counts$days_year - median(FL.nest.counts$days_year)),
          log(FL.nest.counts$distance) - median(log(FL.nest.counts$distance)),
          FL.nest.counts$days_week - median(FL.nest.counts$days_week),
          FL.nest.counts$days_year - median(FL.nest.counts$days_year),
          0)

#jm <- list(length = length(out.names))
loo.out <- list()
Rmax <- vector(mode = "numeric", length = length(out.names))

#length(out.names)
for (k in 1:length(out.names)){
  MCMC.params$model.file = paste0("models/Model_JAGS_negbin_rSlope_rInt_",
                                  model.names[k], ".txt")
  FL.jags.data$X <- X.FL[[k]]

  if (!file.exists(paste0("RData/JAGS_out_negbin_rSlope_rInt_", 
                          out.names[k], "_FL.rds"))){
    
    jm <- jags(data = FL.jags.data,
               #inits = inits,
               parameters.to.save= parameters,
               model.file = MCMC.params$model.file,
               n.chains = MCMC.params$n.chains,
               n.burnin = MCMC.params$n.burnin,
               n.thin = MCMC.params$n.thin,
               n.iter = MCMC.params$n.samples,
               DIC = T, 
               parallel=T)
    
    saveRDS(jm, 
            file = paste0("RData/JAGS_out_negbin_rSlope_rInt_", 
                          out.names[k], "_FL.rds"))
    
  } else {
    jm <- readRDS(file = paste0("RData/JAGS_out_negbin_rSlope_rInt_", 
                                out.names[k], "_FL.rds"))
  }

  Rmax[k] <- max(unlist(lapply(jm$Rhat, FUN = max)))
  
  if (!file.exists(paste0("RData/LOOIC_negbin_rSlope_rInt_", 
                          out.names[k], "_FL.rds"))){
    
    loo.out[[k]] <- compute.LOOIC(loglik = jm$sims.list$loglik, 
                                  data.vector = FL.jags.data$count, 
                                  MCMC.params = MCMC.params)
    saveRDS(loo.out[[k]], 
            file = paste0("RData/LOOIC_negbin_rSlope_rInt_", 
                          out.names[k], "_FL.rds"))
    
  } else {
    loo.out[[k]] <- readRDS(file = paste0("RData/LOOIC_negbin_rSlope_rInt_",
                                          out.names[k], "_FL.rds"))
  }
  
}

# summary(jm.FL.3Covs)
# rm(jm.FL.3Covs)
```

Look at the convergence using Rhat statistic:

```{r}
Rmax
```

They didn't converge... 

```{r}

```


Then... use LOOIC or DIC to compare these models. 

```{r}
loo.all <- lapply(loo.out, FUN = function(X) X$loo.out) %>%
  lapply(FUN = function(X){ X$estimates %>% data.frame() %>% 
      rownames_to_column(var = "Statistic")})

looic <- lapply(loo.all, FUN = function(X) filter(X, Statistic == "looic") %>% select(Estimate))
unlist(looic)
```


Looks like the 3 covariate model is the best. Pareto k statistic isn't great though... About 34% were > 0.7. Should we be concerned? 

```{r}
sum(loo.out[[1]]$loo.out$diagnostics$pareto_k > 0.7)/length(FL.jags.data$count)
```


Take a look at which ones are bad ones

```{r}
idx.bad.looic <- loo.out[[1]]$loo.out$diagnostics$pareto_k > 0.7

FL.paretok.data <- data.frame(beach = FL.jags.data$beach,
                            count = FL.jags.data$count,
                            yearc = FL.jags.data$yearc,
                            year = FL.nest.counts$year,
                            pareto_k = loo.out[[1]]$loo.out$diagnostics$pareto_k)

ggplot(data = FL.paretok.data) +
  geom_point(aes(x = beach, 
                 y = yearc, 
                 color = pareto_k)) +
  scale_color_continuous(type = "viridis")
```

Some beaches are not good throughout their data, whereas others are okay... This means that we may need a different model to accommodate all... 

Take a look at residuals
```{r}
jm <- readRDS(file = paste0("RData/JAGS_out_negbin_rSlope_rInt_", out.names[1], "_FL.rds"))

summary.df <- jm$summary %>% data.frame() %>% rownames_to_column(var = "Parameter")

# regular expression - ^a0 means the beginning of a string has to be a0
# \\[ are the escape characters for [, which is a reserved character. 
# ([0-9]+) means numbers 
# \\] also to literal ]
summary.a0.df <- summary.df[grep(pattern = "^a0\\[([0-9]+)\\]", x = summary.df$Parameter),]
summary.a1.df <- summary.df[grep(pattern = "^a1\\[([0-9]+)\\]", x = summary.df$Parameter),]

grep(pattern = ".+\\[([0-9]+)\\].+?$", x = summary.df$Parameter)
summary.beta1.df <- summary.df[grep(pattern = "beta[1]", x = summary.df$Parameter, fixed = TRUE),]
summary.beta2.df <- summary.df[grep(pattern = "beta[2]", x = summary.df$Parameter, fixed = TRUE),]
summary.beta3.df <- summary.df[grep(pattern = "beta[3]", x = summary.df$Parameter, fixed = TRUE),]

resid <- log.mu <- vector(mode = "numeric", length = length(FL.jags.data$count))
beach <- FL.jags.data$beach
yearc <- FL.jags.data$yearc
X <- X.FL[[1]]
for (i in 1:length(FL.jags.data$count)){
  log.mu[i] <- summary.a0.df[beach[i], "mean"] + 
    summary.a1.df[beach[i], "mean"] * yearc[i] + 
    summary.beta1.df[1, "mean"] * X[i,1] + 
    summary.beta2.df[1, "mean"] * X[i,2] + 
    summary.beta3.df[1, "mean"] * X[i,3]
  
  resid[i] <- FL.jags.data$count[i] - exp(log.mu[i])
}

summary.loglik.df <- summary.df %>% filter(str_detect(Parameter, "loglik"))
                                           
FL.paretok.data$residual <- resid
FL.paretok.data$mu <- exp(log.mu)
FL.paretok.data$loglik <- summary.loglik.df$mean

# remove pareto_k < 0.7 because they are supposedly okay.

FL.paretok.data %>% filter(pareto_k > 0.7) -> FL.paretok.data.2
ggplot(data = FL.paretok.data.2) +
  geom_point(aes(x = beach, 
                 y = yearc,
                 color = abs(residual)))+
  scale_color_continuous(type = "viridis")

```
Only a few beaches have horrible residuals. Is there a relationship between residuals and  Pareto k?

```{r}

ggplot(data = FL.paretok.data.2) +
  geom_point(aes(x = residual, 
                 y =  pareto_k)) 
#  scale_color_continuous(type = "viridis")

```
Not really a relationship there... 


```{r}

ggplot(data = FL.paretok.data.2) +
  geom_point(aes(x = count, 
                 y =  mu,
                 color = pareto_k))  +
  scale_color_continuous(type = "viridis")

```

There is no particular pattern between Pareto k and observed count or estimated mu. 

How can I make the model more flexible? 

START HERE 2020-09-11

```{r}
mcmc_trace(jm.FL$samples, c("beta[1]", "beta[2]", "beta[3]" ))
```

These look okay. 

Take a look at the over-dispersion variance parameter.

```{r}
mcmc_dens(jm.FL$samples, pars = "sigma.e")
```

It's a little greater than 0, but not much... 

Extract population growth parameters. 

```{r}
FL.summary.df <- data.frame(jm.FL$summary) %>%
  rownames_to_column("Parameter")

FL.summary.df %>% 
  filter(str_detect(Parameter, pattern = "a1pc")) %>%
  rownames_to_column("beach") %>%
  transmute(ID = as.numeric(beach),
            mean_a1pc = mean,
            sd_a1pc = sd,
            low25_a1pc = X2.5.,
            median_a1pc = X50.,
            upper975_a1pc = X97.5.)-> FL.a1pc

FL.a1pc %>% 
  left_join(FL.lat.dat, by = "ID") %>%
  arrange(latc) -> FL.a1pc

FL.summary.df %>% 
  filter(str_detect(Parameter, pattern = "mu.a1")) %>%
  rownames_to_column("beach") %>%
  transmute(ID = as.numeric(beach),
            mean_mu.a1 = mean,
            sd_mu.a1 = sd,
            low25_mu.a1 = X2.5.,
            median_mu.a1 = X50.,
            upper975_mu.a1 = X97.5.)-> FL.mu.a1

FL.mu.a1 %>% left_join(FL.lat.dat, by = "ID") %>%
  arrange(latc) -> FL.mu.a1

#head(a1pc.2008)
```


Look at the beach specific annual growth rate in %:

```{r}

ggplot() + 
  geom_point(data = FL.a1pc, 
             aes(x = beach, y = mean_a1pc),
             color = "blue") + 
  geom_errorbar(data = FL.a1pc,
                aes(ymin = low25_a1pc,
                    ymax = upper975_a1pc,
                    x = beach),
                color = "blue") + 
  ylab("Annual average growth rate (%) and 95% CI") + 
  xlab("Beach ID")
```

Create a table with beach names:

```{r}
FL.a1pc %>% select(ID, name, mean_a1pc, sd_a1pc, low25_a1pc, upper975_a1pc) -> FL.table

write_csv(FL.table, path = "data/FL_growth_rates_Sept2020.csv")
```



STX

```{r}
# The X matrix for STX is not useful because there is only one beach, except the number of days per year surveyed. 
X.STX <- cbind(STX.nest.counts$distance - median(STX.nest.counts$distance),
                STX.nest.counts$days_week - median(STX.nest.counts$days_week),
                STX.nest.counts$days_year - median(STX.nest.counts$days_year))

STX.jags.data <- list(N = length(STX.nest.counts$nests),
                      nbeach = length(unique(STX.nest.counts$ID2)),
                      count = STX.nest.counts$nests,
                      beach = STX.nest.counts$ID2,
                      yearc = (STX.nest.counts$year - median(STX.nest.counts$year)),
                      X = X.STX)

                      # latc = STX.lat.dat$latc,
                      # latc2 = STX.lat.dat$latc2)


```

The original model doesn't work for just one beach. I can add STX and PR to the FL dataset and analyze them all at once. Or 
Then run the model for STX. Note that some covariates in the original model are unavailable. I changed it. 

```{r}
parameters <- c("a0", "a1", "beta", "B.hat", "a1pc",
                "mu.a0", "mu.a1",
                "rea0", "rea1",
                "delta1", "delta2",
                "sigma.e", "Sigma.B",
                "sigma.a0", "sigma.a1",
                "floridapc", "probP", "deviance",
                "Devobs", "Devpred")

MCMC.params$model.file = "models/Model_JAGS_rSlope_rInt_3Covs.txt"



if (!file.exists("RData/JAGS_out_Dist_rSlope_rInt_3Covs_2008.rds")){
  jm.2008 <- jags(data = jags.data.2008,
             #inits = inits,
             parameters.to.save= parameters,
             model.file = MCMC.params$model.file,
             n.chains = MCMC.params$n.chains,
             n.burnin = MCMC.params$n.burnin,
             n.thin = MCMC.params$n.thin,
             n.iter = MCMC.params$n.samples,
             DIC = T, 
             parallel=T)
  
  saveRDS(jm.2008, file = "RData/JAGS_out_Dist_rSlope_rInt_3Covs_2008.rds")
  
} else {
  jm.2008 <- readRDS("RData/JAGS_out_Dist_rSlope_rInt_3Covs_2008.rds")
}

summary(jm.2008)
```

At least they converged fine! 

Note that beach IDs are ID2, not the original ID numbers. So, we need to make sure right ones are used. 

```{r}
summary.2008.df <- data.frame(jm.2008$summary) %>%
  rownames_to_column("Parameter")

# find the beach-specific growth rate in percent
#mcmc_trace(jm.MS$samples, pars = "a1pc[38]")

summary.2008.df %>% filter(str_detect(Parameter, pattern = "a1pc")) %>%
  rownames_to_column("beach") %>%
  transmute(ID = as.numeric(beach),
            mean_a1pc = mean,
            sd_a1pc = sd,
            low25_a1pc = X2.5.,
            median_a1pc = X50.,
            upper975_a1pc = X97.5.)-> a1pc.2008

a1pc.2008 %>% left_join(lat.dat.2008, by = "ID") %>%
  arrange(latc) -> a1pc.2008

summary.2008.df %>% 
  filter(str_detect(Parameter, pattern = "mu.a1")) %>%
  rownames_to_column("beach") %>%
  transmute(ID = as.numeric(beach),
            mean_mu.a1 = mean,
            sd_mu.a1 = sd,
            low25_mu.a1 = X2.5.,
            median_mu.a1 = X50.,
            upper975_mu.a1 = X97.5.)-> mu.a1.2008

mu.a1.2008 %>% left_join(lat.dat.2008, by = "ID") %>%
  arrange(latc) -> mu.a1.2008

#head(a1pc.2008)
```


Look at why a1pc.2008 is quite different from a1pc.new...

Compare results visually...
```{r}

ggplot() + 
  geom_point(data = a1pc, 
             aes(x = beach, y = mean_a1pc),
             color = "blue") + 
  geom_errorbar(data = a1pc,
                aes(ymin = low25_a1pc,
                    ymax = upper975_a1pc,
                    x = beach),
                color = "blue") + 
  geom_point(data = a1pc.new, 
             aes(x = beach, y = mean_a1pc),
             color = "red") + 
  geom_errorbar(data = a1pc.new,
                aes(ymin = low25_a1pc,
                    ymax = upper975_a1pc,
                    x = beach),
                color = "red") + 
  geom_point(data = a1pc.2008, 
            aes(x = ID, y = mean_a1pc),
            color = "green") + 
  geom_errorbar(data = a1pc.2008,
              aes(ymin = low25_a1pc,
                  ymax = upper975_a1pc,
                  x = ID),
              color = "green")

```
