---
title: "R Notebook"
output: html_notebook
---


Trend analysis of leatherback turtles nesting in Florida with Kelly Stewart.

New data were received in August 2020. 

```{r}
rm(list=ls())
library(tidyverse)
library(ggplot2)
library(readr)
library(lubridate)
library(jagsUI)
library(bayesplot)
library(stringr)

source("Caribbean_Dc_fcns.R")

MCMC.params <- list(n.samples = 75000,
                    n.burnin = 55000,
                    n.thin = 5,
                    n.chains = 5)

n.per.chain <- (MCMC.params$n.samples - MCMC.params$n.burnin)/MCMC.params$n.thin

```

Get data;

```{r}
col.def <- cols(ID = col_integer(),
                year = col_integer(),
                beach = col_character(),
                latitude = col_double(),
                distance = col_double(),
                days_week = col_integer(),
                days_year = col_integer(),
                nests = col_integer())

FL.nest.counts <- read_csv("data/FL_Sept2020.csv", 
                           col_types = col.def) %>% 
  mutate(beach_f = as.factor(toupper(beach)),
         dataset = "FL",
         ID2 = as.numeric(as.factor(ID)))


```

Change in abundance over time at each beach can be seen in FL_PR_STX_v0_Sept2020.Rmd. 

For FL, we can fit the same models as the last publication. I use the same set of covariates but also test all possibilities of 3 covariates to see which set is the best.  

```{r}

FL.nest.counts %>% 
  group_by(ID2) %>%
  summarise(n = n()) -> FL.ns

FL.nest.counts %>% 
  select(ID2, ID, latitude, beach_f, year) %>% 
  group_by(ID) %>%
  summarise(ID2 = first(ID2),
            name = first(beach_f),
            latitude = first(latitude),
            median.yr = median(year),
            min.yr = min(year),
            n = n()) %>%
  mutate(latc = latitude - mean(latitude),
         latc2 = latc^2,
         beach = ID,
         ID2 = ID2,
         name = name) -> FL.lat.dat

median.yr <- select(FL.lat.dat, c(ID, median.yr, min.yr)) %>%
  right_join(FL.nest.counts, by = "ID") %>% 
  select(ID, median.yr, min.yr, year)

# changed from centering to left-adjusted for years. I think t >= 0 makes more
# sense explaining the intercept than centering time. With t >= 0, it is the 
# log(mu) at time 0 for each beach, whereas if time is centered, it is log(mu) at
# some arbitrary year for each beach. 

FL.jags.data <- list(N = length(FL.nest.counts$nests),
                     nbeach = length(unique(FL.nest.counts$ID2)),
                     count = FL.nest.counts$nests,
                     beach = FL.nest.counts$ID2,
                     yearc = median.yr$year - median.yr$min.yr,
                     latc = FL.lat.dat$latc,
                     latc2 = FL.lat.dat$latc2)

data.vector <- FL.jags.data$count %>% 
  rep(each = MCMC.params$n.chains * n.per.chain)

parameters <- c("a0", "a1", "beta", "B.hat", "a1pc",
                "mu.a0", "mu.a1", "mu",
                "rea0", "rea1",
                "delta1", "delta2",
                "sigma.e", "Sigma.B",
                "sigma.a0", "sigma.a1",
                "floridapc", "probP", "deviance",
                "Devobs", "Devpred", "loglik")

```


```{r}
# reduced set of models as of Sept 2020. I can't remember why I removed
# "beach" as a covariate... 
# Found this comment "Looks like some parameters/models converged fine. Those with beach-specific betas didn't converge well."
# I think that's the reason the beach covariate was removed. 

model.names <- c("3Covs", rep("2Covs", times = 3), 
                 rep("1Cov", times = 3), "0Cov")
out.names <- c("3Covs", "logD_DayWk", "logD_DayYr", "DayWk_DayYr",
               "logD", "DayWk", "DayYr", "0Cov") 

# model.names <- c("3Covs", "3Covs_beach", 
#                  rep("2Covs", times = 3),
#                  rep("2Covs_beach", times = 3),
#                  rep("1Cov", times = 3),
#                  rep("1Cov_beach", times = 3),"0Cov")
# out.names <- c("3Covs", "3Covs_beach", 
#                "logD_DayWk", "logD_DayYr", "DayWk_DayYr",
#                "logD_DayWk_beach", "logD_DayYr_beach", "DayWk_DayYr_beach",
#                "logD", "DayWk", "DayYr", 
#                "logD_beach", "DayWk_beach", "DayYr_beach", "0Cov") 
X.FL <- list(cbind(log(FL.nest.counts$distance) -
                     median(log(FL.nest.counts$distance)),
                   FL.nest.counts$days_week -
                     median(FL.nest.counts$days_week),
                   FL.nest.counts$days_year -
                     median(FL.nest.counts$days_year)),
             cbind(log(FL.nest.counts$distance) -
                     median(log(FL.nest.counts$distance)),
                   FL.nest.counts$days_week -
                     median(FL.nest.counts$days_week)),
             cbind(log(FL.nest.counts$distance) -
                     median(log(FL.nest.counts$distance)),
                   FL.nest.counts$days_year -
                     median(FL.nest.counts$days_year)),
             cbind(FL.nest.counts$days_week -
                     median(FL.nest.counts$days_week),
                   FL.nest.counts$days_year -
                     median(FL.nest.counts$days_year)),
             log(FL.nest.counts$distance) -
               median(log(FL.nest.counts$distance)),
             FL.nest.counts$days_week - 
               median(FL.nest.counts$days_week),
             FL.nest.counts$days_year - 
               median(FL.nest.counts$days_year),
             0)

#jm <- list(length = length(out.names))
loo.out <- list()
Rmax <- vector(mode = "numeric", length = length(out.names))

for (k in 1:length(out.names)){
  MCMC.params$model.file = paste0("models/Model_JAGS_rSlope_rInt_",
                                  model.names[k], ".txt")
  FL.jags.data$X <- X.FL[[k]]

  if (!file.exists(paste0("RData/JAGS_out_rSlope_rInt_", 
                          out.names[k], "_FL.rds"))){
    jm <- jags(data = FL.jags.data,
               #inits = inits,
               parameters.to.save= parameters,
               model.file = MCMC.params$model.file,
               n.chains = MCMC.params$n.chains,
               n.burnin = MCMC.params$n.burnin,
               n.thin = MCMC.params$n.thin,
               n.iter = MCMC.params$n.samples,
               DIC = T, 
               parallel=T)
    
    saveRDS(jm, 
            file = paste0("RData/JAGS_out_rSlope_rInt_", 
                          out.names[k], "_FL.rds"))
    
  } else {
    jm <- readRDS(file = paste0("RData/JAGS_out_rSlope_rInt_",
                                out.names[k], "_FL.rds"))
  }

  Rmax[k] <- max(unlist(lapply(jm$Rhat, FUN = max)))
  
  if (!file.exists(paste0("RData/LOOIC_rSlope_rInt_", 
                          out.names[k], "_FL.rds"))){
    loo.out[[k]] <- compute.LOOIC(loglik = jm$sims.list$loglik, 
                                  data.vector = FL.jags.data$count, 
                                  MCMC.params = MCMC.params)
    saveRDS(loo.out[[k]], 
            file = paste0("RData/LOOIC_rSlope_rInt_",
                          out.names[k], "_FL.rds"))
    
  } else {
    loo.out[[k]] <- readRDS(file = paste0("RData/LOOIC_rSlope_rInt_",
                                          out.names[k], "_FL.rds"))
  }
  
}

loo.all <- lapply(loo.out, FUN = function(X) X$loo.out) %>%
  lapply(FUN = function(X){ 
    X$estimates %>% 
      data.frame() %>% 
      rownames_to_column(var = "Statistic")}) %>%
  lapply(FUN = function(X) filter(X, Statistic == "looic") 
         %>% select(Estimate)) %>%
  unlist()

looic.df.Poi <- data.frame(ID = seq(1, length(model.names)),
                           model = model.names,
                           cov = out.names,
                           looic = loo.all,
                           MaxRhat = Rmax) %>%
  arrange(-desc(looic))



# summary(jm.FL.3Covs)
# rm(jm.FL.3Covs)
```

Then... use LOOIC or DIC to compare these models. 

```{r}
looic.df.Poi
```


Looks like the 3 covariate model is the best. Pareto k statistic isn't great though... About 34% were > 0.7. Should we be concerned? Not really... 

```{r}
sum(loo.out[[looic.df.Poi[1,"ID"]]]$loo.out$diagnostics$pareto_k > 0.7)/length(FL.jags.data$count)
```


Take a look at which ones are bad ones

```{r}
idx.bad.looic <- loo.out[[looic.df.Poi[1,"ID"]]]$loo.out$diagnostics$pareto_k > 0.7

FL.paretok.data <- data.frame(beach = FL.jags.data$beach,
                            count = FL.jags.data$count,
                            yearc = FL.jags.data$yearc,
                            year = FL.nest.counts$year,
                            pareto_k = loo.out[[looic.df.Poi[1,"ID"]]]$loo.out$diagnostics$pareto_k)

ggplot(data = FL.paretok.data) +
  geom_point(aes(x = beach, 
                 y = yearc, 
                 color = pareto_k)) +
  scale_color_continuous(type = "viridis")
```

Some beaches are not good throughout their data, whereas others are okay... This means that we may need a different model to accommodate all... 

Take a look at residuals
```{r}
jm <- readRDS(file = paste0("RData/JAGS_out_rSlope_rInt_", 
                            out.names[looic.df.Poi[1,"ID"]], "_FL.rds"))

summary.df <- jm$summary %>% data.frame() %>% rownames_to_column(var = "Parameter")

# regular expression - ^a0 means the beginning of a string has to be a0
# \\[ are the escape characters for [, which is a reserved character. 
# ([0-9]+) means numbers 
# \\] also to literal ]
summary.a0.df <- summary.df[grep(pattern = "^a0\\[([0-9]+)\\]", 
                                 x = summary.df$Parameter),] %>%
  rownames_to_column("beach") %>% mutate(ID = as.numeric(beach))
summary.a1.df <- summary.df[grep(pattern = "^a1\\[([0-9]+)\\]", 
                                 x = summary.df$Parameter),]

#grep(pattern = ".+\\[([0-9]+)\\].+?$", x = summary.df$Parameter)

# summary.mu.df <- summary.df[grep(pattern = "^mu\\[([0-9]+)\\]", 
#                                  x = summary.df$Parameter),] %>%
#   mutate(beach = FL.jags.data$beach)

summary.beta1.df <- summary.df[grep(pattern = "beta[1]", 
                                    x = summary.df$Parameter, 
                                    fixed = TRUE),]
summary.beta2.df <- summary.df[grep(pattern = "beta[2]", 
                                    x = summary.df$Parameter, 
                                    fixed = TRUE),]
summary.beta3.df <- summary.df[grep(pattern = "beta[3]", 
                                    x = summary.df$Parameter, 
                                    fixed = TRUE),]

resid <- log.mu <- vector(mode = "numeric", 
                          length = length(FL.jags.data$count))
beach <- FL.jags.data$beach
yearc <- FL.jags.data$yearc
X <- X.FL[[1]]
for (i in 1:length(FL.jags.data$count)){
  log.mu[i] <- summary.a0.df[beach[i], "mean"] + 
    summary.a1.df[beach[i], "mean"] * yearc[i] + 
    summary.beta1.df[1, "mean"] * X[i,1] + 
    summary.beta2.df[1, "mean"] * X[i,2] + 
    summary.beta3.df[1, "mean"] * X[i,3]
  
  resid[i] <- FL.jags.data$count[i] - exp(log.mu[i])
}

summary.loglik.df <- summary.df %>% 
  filter(str_detect(Parameter, "loglik"))
                                           
FL.paretok.data$residual <- resid
FL.paretok.data$mu <- exp(log.mu)
FL.paretok.data$loglik <- summary.loglik.df$mean

# remove pareto_k < 0.7 because they are supposedly okay.

FL.paretok.data %>% filter(pareto_k > 0.7) -> FL.paretok.data.2
ggplot(data = FL.paretok.data.2) +
  geom_point(aes(x = beach, 
                 y = yearc,
                 color = abs(residual)))+
  scale_color_continuous(type = "viridis")

```
Only a few beaches have horrible residuals. Is there a relationship between residuals and  Pareto k?

```{r}

ggplot(data = FL.paretok.data.2) +
  geom_point(aes(x = residual, 
                 y =  pareto_k)) 
#  scale_color_continuous(type = "viridis")

```
Not really a relationship there... 


```{r}

ggplot(data = FL.paretok.data.2) +
  geom_point(aes(x = count, 
                 y =  mu,
                 color = pareto_k))  +
  scale_color_continuous(type = "viridis")

```

There is no particular pattern between Pareto k and observed count or estimated mu. 

How can I make the model more flexible? 

I tried the negative binomial distribution in a couple ways instead of Poisson but it didn't work as expected. I might have used the distribution incorrectly. Kelly wanted to use the same model as before so let's move on for now. 

For STX, I used log-normal distribution and they worked better than the Poisson models. So, I'll give that a try for FL data. None of them converged so sticking with the Poisson models. 


One thing I noticed at this point is that many have the same pattern where the nest counts started to decline around 2010. 

As I did for the STX dataset, it may be good to have two slopes with a change-point parameter. 

```{r}
parameters <- c("a0.1", "a1.1", "a0.2", "a1.2",
                "beta", "B.1", "B.2", 
                "delta1", "delta2", 
                "year.change",
                "sigma.e",
                "sigma.a0.1", "sigma.a1.1", 
                "sigma.a0.2", "sigma.a1.2", "loglik")

FL.jags.data.2slopes <- list(N = length(FL.nest.counts$nests),
                             nbeach = length(unique(FL.nest.counts$ID2)),
                             count = FL.nest.counts$nests,
                             beach = FL.nest.counts$ID2,
                             yearc = median.yr$year - min(median.yr$min.yr),
                             latc = FL.lat.dat$latc,
                             latc2 = FL.lat.dat$latc2,
                             minT = 25, maxT = 37)


# For these models, years have to be the same across the board because 
# I assume the change point is happening at the same time for all beaches
# 1979 = 0

#jm <- list(length = length(out.names))
loo.out <- list()
Rmax <- vector(mode = "numeric", length = length(out.names))
k <- 1
for (k in 1:length(out.names)){
  MCMC.params$model.file = paste0("models/Model_JAGS_r2Slopes_rInt_",
                                  model.names[k], ".txt")
  FL.jags.data.2slopes$X <- X.FL[[k]]

  if (!file.exists(paste0("RData/JAGS_out_r2Slopes_rInt_", 
                          out.names[k], "_FL.rds"))){
    jm <- jags(data = FL.jags.data.2slopes,
               #inits = inits,
               parameters.to.save= parameters,
               model.file = MCMC.params$model.file,
               n.chains = MCMC.params$n.chains,
               n.burnin = MCMC.params$n.burnin,
               n.thin = MCMC.params$n.thin,
               n.iter = MCMC.params$n.samples,
               DIC = T, 
               parallel=T)
    
    saveRDS(jm, 
            file = paste0("RData/JAGS_out_r2Slopes_rInt_", 
                          out.names[k], "_FL.rds"))
    
  } else {
    jm <- readRDS(file = paste0("RData/JAGS_out_r2Slopes_rInt_",
                                out.names[k], "_FL.rds"))
  }

  Rmax[k] <- max(unlist(lapply(jm$Rhat, FUN = max)), na.rm = T)
  
  if (!file.exists(paste0("RData/LOOIC_r2Slopes_rInt_", 
                          out.names[k], "_FL.rds"))){
    loo.out[[k]] <- compute.LOOIC(loglik = jm$sims.list$loglik, 
                                  data.vector = FL.jags.data$count, 
                                  MCMC.params = MCMC.params)
    saveRDS(loo.out[[k]], 
            file = paste0("RData/LOOIC_r2Slopes_rInt_",
                          out.names[k], "_FL.rds"))
    
  } else {
    loo.out[[k]] <- readRDS(file = paste0("RData/LOOIC_r2Slopes_rInt_",
                                          out.names[k], "_FL.rds"))
  }
  
}

loo.all <- lapply(loo.out, FUN = function(X) X$loo.out) %>%
  lapply(FUN = function(X){ 
    X$estimates %>% 
      data.frame() %>% 
      rownames_to_column(var = "Statistic")}) %>%
  lapply(FUN = function(X) filter(X, Statistic == "looic") 
         %>% select(Estimate)) %>%
  unlist()

looic.df.Poi.2slopes <- data.frame(ID = seq(1, length(model.names)),
                                   model = model.names,
                                   cov = out.names,
                                   looic = loo.all,
                                   MaxRhat = Rmax,
                                   dLOOIC = loo.all - min(loo.all)) %>%
  arrange(-desc(looic))


looic.df.Poi.2slopes

```


The 3-covariate model seems best, although the first four models came back with MaxRhat = NA first... 

```{r}

ID <- 1
jm <- readRDS(file = paste0("RData/JAGS_out_r2Slopes_rInt_",
                            out.names[ID], "_FL.rds"))

mcmc_trace(jm$samples, c("a0.1[1]", "a1.1[1]", "a0.2[1]", "a1.2[1]"))  
```


```{r}
mcmc_trace(jm$samples, c("a0.1[10]", "a1.1[10]", 
                         "a0.2[10]", "a1.2[10]"))  
```


```{r}
mcmc_trace(jm$samples, c("delta1", "delta2", "beta[1]", "beta[2]"))  

```

```{r}
mcmc_trace(jm$samples, c("sigma.a0.1", "sigma.a1.1", 
                         "sigma.a0.2", "sigma.a1.2"))  

```

```{r}
mcmc_trace(jm$samples, c("year.change"))  
```

When using a POI prior for year.change, the posterior density was on one point (mean value). Using the uniform prior, it seemed to converge fine between 30 and 31. So, that's a lot better. Although the density is flat between 30 and 31... prior was from 25 to 37. 

```{r}
mcmc_dens(jm$samples, c("year.change"))
```


Goodness-of-fit

```{r}
prop.high.pareto.k.Poisson <- sum(loo.out[[looic.df.Poi.2slopes[1,"ID"]]]$loo.out$diagnostics$pareto_k > 0.7)/length(FL.jags.data$count)

plot(loo.out[[looic.df.Poi.2slopes[1,"ID"]]]$loo.out)
```

There are some high values... 


